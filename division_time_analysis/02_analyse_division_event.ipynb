{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb148a2d-d041-42f4-876a-5b4d2eaf9c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../SyMBac/')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from joblib import Parallel, delayed\n",
    "from glob import glob\n",
    "from skimage.filters.thresholding import threshold_isodata, threshold_li, threshold_mean, threshold_otsu, \\\n",
    "    threshold_local, threshold_niblack, threshold_sauvola\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from skimage.measure import label\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b692fe2-25a9-4836-b823-942d06d9ab68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cellpose import models, core\n",
    "use_GPU = core.use_gpu()\n",
    "from cellpose import transforms\n",
    "from omnipose.utils import normalize99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accac16a-dc4c-48fb-a65c-26a5f4c82b75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99691288-8497-426a-b21e-0ec16a54ae2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dirs = natsorted(glob(\"synthetic_training_data/models/*2301*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b293521-cc69-470d-a174-2ee7c0040392",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca162b4-c2d9-43d2-9fe2-c83f749e4a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def global_threshold(function, image):\n",
    "    thresh = function(image)\n",
    "    binary = image > thresh\n",
    "    return binary\n",
    "\n",
    "def default_threshold_local(image):\n",
    "    return threshold_local(image, block_size=41)\n",
    "\n",
    "def default_threshold_sauvola(image):\n",
    "    return threshold_sauvola(image, window_size=103)\n",
    "\n",
    "def default_threshold_niblack(image):\n",
    "    return threshold_niblack(image, window_size=103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ea116-add3-4e70-942e-4cf1b777f2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def try_all_global_threshold(image):\n",
    "    functions = [threshold_isodata, threshold_li, threshold_mean, threshold_otsu] \n",
    "    function_names = [\"Isodata\", \"Li\", \"Mean\", \"Otsu\"]\n",
    "    binary_imgs = {}\n",
    "    for function, name in zip(functions, function_names):\n",
    "        try:\n",
    "            binary_imgs[name] = global_threshold(function, image)\n",
    "        except:\n",
    "            binary_imgs[name] = np.nan\n",
    "    #binary_imgs = {name : global_threshold(function, image) for (function, name) in zip(functions, function_names)}\n",
    "    return binary_imgs\n",
    "\n",
    "def try_all_local_threshold(image):\n",
    "    functions = [default_threshold_sauvola, default_threshold_niblack] \n",
    "    function_names = [\"Sauvola\", \"Niblack\"]\n",
    "    binary_imgs = {}\n",
    "    for function, name in zip(functions, function_names):\n",
    "        try:\n",
    "            binary_imgs[name] = global_threshold(function, image)\n",
    "        except:\n",
    "            binary_imgs[name] = np.nan\n",
    "    #binary_imgs = {name : global_threshold(function, image) for (function, name) in zip(functions, function_names)}\n",
    "    return binary_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe0171-932b-494d-934c-48a963d2f113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = sorted(glob(\"synthetic_training_data/*.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7117f-4422-45a5-be2e-c8e86d504d2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_gpu = use_GPU# = False\n",
    "def segment_with_all_methods(image_dir):\n",
    "    all_data = []\n",
    "    image = np.array(Image.open(image_dir))\n",
    "    thresholds = segment_with_omnipose(image, train_type=\"retrained\") | try_all_global_threshold(image) | try_all_local_threshold(image) | segment_with_omnipose(image, train_type=\"bact_fluor_omni\")\n",
    "    for function, image in thresholds.items():\n",
    "        image = np.array_split(image, 15, axis=1)\n",
    "        for i, cell in enumerate(image):\n",
    "            labeled_cell = label(cell)\n",
    "            if len(np.unique(labeled_cell)) > 2:\n",
    "                division_index = i\n",
    "                all_data.append([function, division_index])\n",
    "                break\n",
    "    return all_data\n",
    "for model_dir in model_dirs:\n",
    "    def segment_with_omnipose(image, train_type = \"retrained\"):\n",
    "        if train_type == \"retrained\":\n",
    "            use_gpu = use_GPU# = False\n",
    "            model = models.CellposeModel(gpu=use_gpu, pretrained_model=model_dir, omni=True, concatenation=True)\n",
    "            key = \"Omnipose retrained\"\n",
    "        elif train_type == \"bact_fluor_omni\":\n",
    "            key = \"Omnipose pretrained\"\n",
    "            use_gpu = use_GPU# = False\n",
    "            model = models.CellposeModel(gpu=use_gpu, model_type=\"bact_fluor_omni\", omni=True, concatenation=True)\n",
    "        imgs = [image]\n",
    "\n",
    "\n",
    "        nimg = len(imgs)\n",
    "\n",
    "        for k in range(len(imgs)):\n",
    "            img = transforms.move_min_dim(imgs[k]) # move the channel dimension last\n",
    "            if len(img.shape)>2:\n",
    "                imgs[k] = np.mean(img,axis=-1) # or just turn into grayscale \n",
    "\n",
    "            imgs[k] = normalize99(imgs[k])\n",
    "            chans = [0,0] #this means segment based on first channel, no second channel\n",
    "\n",
    "        n = [0] # make a list of integers to select which images you want to segment\n",
    "        n = range(nimg) # or just segment them all\n",
    "\n",
    "        # define parameters\n",
    "        mask_threshold = -1\n",
    "        verbose = 0 # turn on if you want to see more output\n",
    "        use_gpu = use_GPU #defined above\n",
    "        transparency = True # transparency in flow output\n",
    "        rescale=None # give this a number if you need to upscale or downscale your images\n",
    "        omni = True # we can turn off Omnipose mask reconstruction, not advised\n",
    "        flow_threshold = 0. # default is .4, but only needed if there are spurious masks to clean up; slows down output\n",
    "        resample = True #whether or not to run dynamics on rescaled grid or original grid\n",
    "        masks, flows, styles = model.eval([imgs[i] for i in n],channels=chans,rescale=rescale,mask_threshold=mask_threshold,transparency=transparency,\n",
    "                                          flow_threshold=flow_threshold,omni=omni,resample=resample,verbose=verbose)\n",
    "\n",
    "        masks = masks[0]\n",
    "\n",
    "\n",
    "\n",
    "        return {key : masks}\n",
    "\n",
    "    all_data = Parallel(n_jobs=4)(delayed(segment_with_all_methods)(image_dir) for image_dir in (images))\n",
    "    all_data = (flatten(all_data))\n",
    "\n",
    "    all_data = pd.DataFrame(all_data)\n",
    "    all_data.columns = [\"Thresholding method\", \"Division Index\"]\n",
    "    all_data[\"Division Index\"] -= 9\n",
    "    sns.violinplot(data=all_data, x=\"Division Index\", y=\"Thresholding method\")\n",
    "    plt.plot([0,0],[0,8], c = \"k\")\n",
    "    plt.title(model_dir)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6548ae3-a3df-4e47-9b87-2a29191f9239",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.violinplot(data=all_data.query(\"`Thresholding method` == 'Omnipose retrained' or `Thresholding method` == 'Omnipose pretrained'\"), x=\"Division Index\", y=\"Thresholding method\")\n",
    "plt.plot([0,0],[0,1], c = \"k\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469a473c-9d48-4095-a72a-9bd9fc2bbcfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data.groupby(\"Thresholding method\").var() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17e2e2c-4df0-47b8-80cf-98768fbac70d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#all_data.to_pickle(\"division_data.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
